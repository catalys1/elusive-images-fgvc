<!DOCTYPE html>
<html>
<head>
    <title>Elusive Images</title>
    <link rel='stylesheet' type='text/css' href='style.css'>
</head>

<body>

    <!-- HEADER -->
    <h1 class='center biggger'>Elusive Images: Beyond Coarse Analysis for Fine-grained Recognition</h1>
    <div class='center light-text'>
        Winter Conference on Applications of Computer Vision (WACV) 2024
    </div>
    <br>
    <div class='center bigger'>
        <b>Connor Anderson</b> &emsp; <b>Ryan Farrell</b> <br>
        Brigham Young University
        <br><br>
        <div id='btn-links'>
            <!-- <a href='https://arxiv.org/abs/2110.03091'><button>Paper</button></a> -->
            <a href='https://github.com/catalys1/elusive-images-fgvc'><button>Code</button></a>
            <a href='https://byu.box.com/v/icub-dataset'><button>iCub Dataset</button></a>
        </div>
    </div>


    <!-- ABSTRACT -->
    <div id='abstract' class='section'>
        <h2>Abstract</h2>
        <p>
        While the community has seen many advances in recent years to address the challenging problem
        of Finegrained Visual Categorization (FGVC), progress seems to be slowing&mdash;new
        state-of-the-art methods often distinguish themselves by improving top-1 accuracy by mere
        tenths of a percent. However, across all of the now-standard FGVC datasets, there remain
        sizeable portions of the test data that none of the current state-of-the-art (SOTA) models can
        successfully predict. This paper provides a framework for identifying and studying the errors
        that current methods make across diverse fine-grained datasets. Three models of
        difficulty&mdash;<b>Prediction Overlap</b>, <b>Prediction Rank</b> and <b>Pairwise Class Confusion</b>&mdash;are
        employed to highlight the most challenging sets of images and classes. Extensive experiments
        apply a range of standard and SOTA methods, evaluating them on multiple FGVC domains and
        datasets. Insights acquired from coupling these difficulty paradigms with the careful
        analysis of experimental results suggest crucial areas for future FGVC research, focusing
        critically on the set of elusive images that none of the current models can correctly classify.
        </p>
    </div>


    <!-- CONTRIBUTIONS -->
    <hr>
    <div class="section">
        <h3>Main Contributions</h3>
        <ul>
            <li>We propose a framework for identifying and analyzing challenging images and classes within a dataset,
                using 3 metrics based on aggregate predictions from multiple classification models: <em>prediction
                overlap</em>, <em>prediction rank</em>, and <em>pairwise class confusion</em>. The code is available.
            </li>
            <li>We provide a standardized implementation and training recipe for several state-of-the-art FCVG models,
                allowing for fair comparison and efficient benchmarking. The code is available.
            </li>
            <li>We introduce the iCub dataset, consisting of images of birds from the same species as CUB, but at a
                larger and more challenging scale, and meant to serve as an additional set of validation images for
                analysis.
            </li>
            <li>We utilize the proposed analysis framework to analyze 5 standard FGVC datasets, along with iCub, using
                6 different model types, to identify patterns in challenging images and classes.
            </li>
        </ul>
    </div>


    <!-- METHOD -->
    <hr>
    <div class='section'>
        <h2>Method</h2>
        <p style="color: red">TODO</p>
        <figure>
            <img src="source/overlap-and-rank.png" alt="" width="85%" ></img>
            <figcaption>
                Illusration of <b>prediction overlap</b> (left) and <b>prediction rank</b> (right).
            </figcaption>
        </figure>
        <figure>
            <img src="source/pairwise-confusion.png" alt="" width="90%" ></img>
            <figcaption>
                Illustration of <b>pairwise class confusion</b>.
            </figcaption>
        </figure>
    </div>
    
    <hr>
    <div class='section'>
        <h2>iCub Dataset</h2>
        <p>
        We propose the iCub dataset as an additional large-scale source of validation images for testing
        models trained to recognize birds from the 200 species found in CUB-200. iCub images are sourced
        from <a href="https://www.inaturalist.org">iNaturalist</a>, and have a different visual distribution.
        This allows us to test CUB models on a more difficult set of data to see how they generalize.
        </p>
        <figure>
            <img src="source/icub-samples.png" alt="iCub sample images" width="100%" ></img>
            <figcaption>A random sampling of images from the proposed iCub dataset.</figcaption>
        </figure>
        <figure>
            <img src="source/cub-icub-stats.png" width="100%">
            <figcaption>
                One way iCub differs from CUB is in the spatial distribution of the birds with respect
                to the image; in particular, iCub contains many birds that are small (occupy a small area
                of the image).
            </figcaption>
        </figure>
    </div>

    <!-- RESULTS -->
    <hr>
    <div class='section'>
        <h2>Results</h2>
        <p style="color: red">TODO</p>
        <figure>
            <img src="source/model-accuracy.png" width="90%">
            <figcaption>
                Validation accuracy on 6 datasets using 6 different models with 5 trials each.
            </figcaption>
        </figure>
        <figure>
            <img src="source/prediction-overlap.png" width="90%">
            <figcaption>
                Validation accuracy on 6 datasets using 6 different models with 5 trials each.
            </figcaption>
        </figure>
    </div>



    <!-- CITATION -->
    <hr>
    <div class='section'>
        <h2>Citation</h2>
        <pre>
@inproceedings{anderson2024elusive-images,
  title={Elusive Images: Beyond Coarse Analysis for Fine-grained Recognition},
  author={Anderson, Connor and Gwilliam, Matt and Gaskin, Evelyn and Farrell, Ryan},
  booktitle={WACV},
  year={2024}
}
        </pre>
    </div>

    <div style="margin-bottom: 200px"></div>

</body>
</html>
